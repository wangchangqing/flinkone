package com.king.flink.datastream.kafka;import com.king.flink.datastream.trigger.CountTrigger;import org.apache.flink.api.common.functions.MapFunction;import org.apache.flink.api.common.serialization.SimpleStringSchema;import org.apache.flink.streaming.api.TimeCharacteristic;import org.apache.flink.streaming.api.datastream.DataStreamSource;import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;import org.apache.flink.streaming.api.windowing.time.Time;import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer010;import java.util.Properties;public class KafkaSource {    public static void main(String[] args) throws Exception {        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();        env.setParallelism(1);        env.setStreamTimeCharacteristic(TimeCharacteristic.ProcessingTime);        Properties properties = new Properties();        properties.setProperty("bootstrap.servers", "localhost:9092");        properties.setProperty("group.id", "test");        FlinkKafkaConsumer010<String> flinkKafkaConsumer010 = new FlinkKafkaConsumer010<String>("jsontest", new SimpleStringSchema(), properties);        DataStreamSource<String> stringDataStreamSource = env.addSource(flinkKafkaConsumer010);        stringDataStreamSource.map(new MapFunction<String, Integer>() {            @Override            public Integer map(String s) throws Exception {                return Integer.valueOf(s);            }        }).timeWindowAll(Time.seconds(100)).trigger(CountTrigger.create()).sum(0).print();        env.execute();    }}